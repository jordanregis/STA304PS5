---
title: "How to Make a Hit Song Today"
subtitle: "Using Regression to Predict Song Popularity"
author: "Timothy Regis"
date: "12/9/2020"
output: pdf_document
---

```{r, include = FALSE}
library(tidyverse)
library(MASS)
library(boot)
library(pscl)
```


# Keywords
Generalized Linear Regression, Musical Attributes, Spotify Music Catalog, Song Popularity

# Abstract
Making a hit song can often seem like an impossible task to the average person as the components of a final composition can be extremely complex. In an attempt to uncover these secrets, this paper applies a generalized regression model to a dataset of Spotify's music catalog, and analyzes the effects of different musical characteristics on the song's popularity. The findings of this analysis suggest that the danceability, energy, valence, and speechiness of a song are all strong predictors of a song's popularity today, with danceability and energy showing significant positive correlations and the latter two suggesting negative returns to popularity. While this cannot be considered a 'golden rule' for songmaking, these results can help interested musicians incorporate new factors into their music to better appeal to wider audiences.



# Introduction
The musical industry of today's world is incredibly complex. Differing tastes have given rise to a seemingly endless pool of genres to choose from. This has made it increasingly difficult to uncover just what exactly goes into making a hit song that resonates with the greatest number of listeners. At times, it seems like only a small and exclusive group holds the secret to this as only a select few appear to top the charts on a regular basis. It can easily be assumed that this is a pure fame game, that is, the most famous and flashy artists garner the largest listening bases and thus will take the lead in a popularity contest. However, this assumption ignores both what got the artist to this point, and why people are still listening.

Whether it be the heaviest of heavy metal, the lightest pieces of classical music, or anything in between, a song can take off in popularity for a number of different reasons. To gain a more thorough and logical understanding of this concept, Spotify has computed numerical values for a wide variety of musical factors that can be studied and compared to a song's popularity. This includes things like a song's; valence, energy, danceability, and many more specific traits. All of these characteristics result in songs that either gain massive popularity or succumb to total irrelevancy, never to be streamed again. 

In this paper, this exact process was carried out. Using a generalized linear regression model, I conducted an analysis on the effects of a song's musical traits on its overall popularity to be able to provide a rudimentary framework for creating a 'hit' song in today's world. To accomplish this, I have made use of a large dataset containing data on over 170,000 songs on Spotify's catalog. The regression model was then applied to this dataset using its popularity measure as the dependent variable and a variety of characteristics as independent predictor variables. 

The results of this analysis suggest that a song's popularity is strongly influenced by its danceability and energy level, with more energetic and danceable songs showing much higher popularity. Furthermore, a song's valence and speechiness are both strong predictors of its popularity as well, however, these qualities appear to be negatively correlated with the song's popularity.

An important area not covered by this analysis is the use of advertising space across Spotify's platforms. On all versions, Spotify picks a few artists or specific songs to advertise on a user's homepage. This makes it difficult to find a definitive answer as these advertisements can pull in very large groups of listeners and sway the popularity in the artist's favor. Moreover, based on a user's listening history, Spotify will often re-suggest these songs or others made by the same or similar artists providing the idea that a song's popularity may not be a case of linear growth due to a suggestion bias. While this makes it more difficult to uncover the truth behind what makes a song most popular, the results that have been generated provide a good initial idea of the most important factors in a song's overall popularity. As such, these findings can be taken advantage of by future artists that hope to give their music a slight edge over their competition. 

To begin, Section 2 provides an overview of the dataset used for the analysis and the according modifications that were required. Section 3 lays out the development of the regression model used for this paper along with a brief explanation on the chosen model. In Section 4, the results of this model analysis are displayed along with their interpretations and a validation process is performed on the model. Section 5 features a discussion of these results and the conclusion that these results bring us to. Additionally, in this section, the weaknesses of this analysis are discussed as well as the areas for improvements and future work. Finally, Section 6 is an Appendix section featuring the code used for this analysis, and Section 7 provides references for all sources used for this paper.

# 2 Data Discussion
For the purposes of this analysis, one extremely large dataset containing information on over 170,000 songs in Spotify's catalog was used. This data was gathered using Spotify's Web API software and was set up and organized by a user on Kaggle. Kaggle is an online data science community that allows users to find and create datasets, statistical models, and data science challenges. 

Spotify's Web API toolkit provides access to their massive catalog of data on many songs in their libraries. This data contains a number of calculated values based on the audio features of individual songs, surrounding categories like moods, properties, musical contexts, and much more. To collect the data, this requires setting up a developer account on Spotify's API platform, and then using a package like spotifyr [CITATION] to request this data. Unfortunately, requesting this data directly from Spotify provides information in a very raw format that requires extensive data cleaning in order to create a workable dataset. As such, there are very few large scale datasets available for this data as it is most often used for smaller-scale research.
Luckily, however, a "self-taught data scientist and music enthusiast" on Kaggle [named Yamac Eren Ay], realized this problem and decided to tackle it by creating their own large scale and up to date dataset that covers a very large variety of musical characteristics on over 170,000 songs. They created 5 separate datasets to accomplish this. 
The one used for the purposes of this study was the basic data dataset which features information on each individual track. This contains data covering the tracks' artists, name, year, release date, duration, and a wide range of musical attribute values such as danceability, energy, key, popularity, and more. The other datasets contain this same information but are instead categorized by a song's artists, genres, and year, where musical attribute values are computed as means for each category.

In order to study the relationship between a song's popularity and its musical characteristics, I have selected a few of these attribute values that I felt would be the most influential. 
Selected: popularity (how popular it is), valence (measure of happiness), danceability (measure of dance ableness), energy (measure of energeticness), instumentalness (how many instrument sounds included), speechiness (measure of spoken words included), tempo (a song's tempo).

To begin with cleaning this data, I first had to examine the types of songs included in the dataset. Upon inspection, this dataset appears to have included non-musical tracks along with regular music. This may cause a problem with the predictions of the model due to the fact that their calculated attribute values are much different that those of regular music. 
The issue with cleaning these songs out of the data, however, is that there is no formal designation for the type of track listed. In an attempt to work around this, I used details from Spotify's Web API documents that provided some insight on the values that these irregular tracks are given.
One attribute that stands out as a definer for track type is speechiness, which determines the overall presence of spoken works in a track. In their documentation for this variable, tracks that are awarded scores greater than 0.66 are most likely made entirely of spoken works, these would be things like; audiobooks, podcasts, poetry, etc. A rough and easy solution I used was to simply remove songs with a score greater than 0.66, this  works, but it may also mean that we lose some "actual" musical tracks that are just exceptionally speechy. As there is no clear way to work around this, this solution is what was used to continue.

Further exploration into the dependent variable, song popularity, reveals some very important information on its construction. As explained in their documents, Spotify computes a song's popularity based on the recent listening history of all users. This means that, naturally, songs from older eras will have disproportionately lower popularity scores than songs released in the recent past. Thus, the predicted values generated by the model will be suggestive of what makes a song most popular today, rather than an absolute definition of how to make the most popular song of all time.
Moreover, due to this style of calculation, this leaves the popularity variable with many zero score songs, likely due to their high age or irregular track type. These zero scores will likely result in less strong predictions as their attribute values are still calculated as constants. Due to this bias, the decision was made to remove all songs with a popularity score of zero, while this may result in losing some songs that were really just a horrible mix of tunes, the increased performance of the model greatly outweighs this loss. 

This decision, however, does raise some concerns with what exact value we should decide to make the boundary. It is likely that songs with popularity scores anywhere between 1 and 10 also have irregularities in their style, and thus should not be included, but as popularity score increases, the likelihood of more "proper" songs ending up cut out of the model will increase as well. Thus, zero is the safe choice that was used.


To begin exploration, using ggplot [CITATION], the distributions of the variables were plotted to see how they are set up and check for any more irregularities.


```{r, include=FALSE}
rawdata <- read_csv("spotifydata.csv")
```

```{r, include=FALSE}
data <- rawdata %>%
  dplyr::select(artists,
                name,
                popularity,
                danceability,
                valence,
                energy, 
                instrumentalness, 
                speechiness, 
                tempo) %>%
  filter(popularity > 0,
         speechiness < 0.66)
```


```{r, echo=FALSE}
data %>%
  ggplot(aes(x = popularity)) + 
  geom_density()
```

Figure ___ plots the density distribution of song popularity from the data. As we can see, this distribution is somewhat bell shaped, but grows extremely large as values approach zero. As was mentioned in the earlier data discussion, this is likely due to the number of older or irregular tracks that were not cut out of the final data. This will likely cause some problems with the model's predictive capabilities and must be kept in mind as we progress.
Besides this issue, the data appears to be significantly clustered between scores of about 20 to 60, with very few songs reaching scores past 75. This observation helps to highlight the extremely competitive environment the music industry is in currently.







```{r, include = FALSE}
mean(data$popularity)
sd(data$popularity)
```


```{r, echo=FALSE}
data %>%
  ggplot(aes(x = valence)) + 
  geom_density()
```
Figure ___ plots the distribution of valence scores given to songs in the dataset. A song's valence is a measure of the musical positiveness the track conveys, where moody and depressing songs score values closer to 0, and upbeat and cheerful songs score closer to 1. The distribution is very even but falls off as values get closer to either extreme. This is unsurprising given the wide variety of moods that artists choose to centre their music around. 




```{r, echo=FALSE}
data %>%
  ggplot(aes(x = energy)) + 
  geom_density()
```
In Figure ___, the distribution of energy scores for songs is displayed. A song's energy score is measured from 0 to 1, and pertains specifically to its intensity and activity, with faster and louder songs earning scores closer to 1 . The distribution here appears to be highest around middle values suggesting somewhat of a balance between high and low energy attributes that most artists aim for. As was expected, this distribution quickly falls off as we approach either extreme.


```{r, echo=FALSE}
data %>%
  ggplot(aes(x = danceability)) + 
  geom_density()
```

Figure ___ displays the distribution of danceability scores given to the songs. Danceability is a rather interesting variable that tracks how suitable a song is for dancing to. This value ranges from 0 to 1 and is based on a variety of musical attributes like tempo, rhythm stability, beat strength, and regularity. As we can see, the majority of songs have scores around 0.55 and resemble somewhat of a normal distribution as we go out from this point.  

```{r, echo=FALSE}
data %>%
  ggplot(aes(x = speechiness)) + 
  geom_density()
```
In Figure ___, the distribution for a song's speechiness is plotted. As mentioned earlier, speechiness measures the amount of spoken word featured in a track, and Spotify explains that tracks scoring over 0.66 are mostly entirely spoken word. Due to this, these tracks were removed from the final data and thus we see the distribution here from zero to less than 0.66. As we can see, the largest amount of this distribution is centered around 0.05, suggesting that most of the songs featured are largely instrumental. This may be partially due to the number of irregular tracks that were not cut out of the final data, however, it is difficult to cut out these values due to the extensive list of music genres that also feature little to no spoken words. 

```{r, echo=FALSE}
data %>%
  ggplot(aes(x = tempo)) + 
  geom_density()
```
Figure ___ plots the distribution of the final variable of interest, tempo. This value simply tracks the overall tempo of a track, or speed and pace, in beats per minute. The distribution is heavily grouped around middle values, with very few songs featuring tempos below 60 or above 180. This observation is unsurprising when we consider what songs featuring these irregular tempos would actually sound like. 



# 3 Model Development

For the purposes of this study, a generalized linear regression model of the quasipoisson was used to analyze the relationship between our dependent and independent variables. A generalized linear model is a generalization of ordinary least squares linear regression which removes the strict assumptions made by the linear model. This model then allows us to link our dependent variable through a specified probability distribution, which we refer to as the family of our regression model. Thus, unlike in linear regression, we do not need to have a normally distributed response variable. 

```{r, include=FALSE}
model <- glm(popularity ~ danceability + speechiness + energy + valence, data = rawdata, family = "quasipoisson")
```

This decision was made for a couple of reasons. First, since we are dealing with real and very messily distributed data, a regular linear regression model would not be sufficient as our data would not be able to satisfy any of its harsh restrictions. Thus, a generalized regression model was highly favoured here. To determine the family of the model this requires examining the design of our dependent variable, popularity. Popularity is measured as count data, which works specifically well with poisson style distributions. The issue with a poisson family, however, is that it requires equal dispersion, that is equivalent mean and variance values. This is not something that our popularity variable satisfies, and thus we need to find a similar distribution that doesn't make this same requirement. This leaves us with a few options such as, negative binomial, or quasipoisson. These distributions both have somewhat similar requirements, but, due to the distribution of the popularity variable, the quasipoisson model was favoured.

To create the model, I have chosen four predictor variables to measure against a song's popularity; danceability, speechiness, energy, and valence. The results of using these predictors in the generalized regression model selected are displayed in Section 4 below.

# 4 Model Results

## 4.1 Summary

Table ___
```{r, echo=FALSE}
summary(model)
```
This section identifies the core predictions made by the regression model. 
Table ___ displays the output from the model using summary statistics, this includes the coefficient's estimate, standard error, t-value, and p-value. 

This table provides us with our first look at the final regression model we will be using:

**log(P) = B0 + B1*D + B2*S + B3*E + B4*V**

Where:
P represents the song's popularity. 
D represents the song's danceability score.
S represents the song's speechiness level.
E represents the song's energy level.
V represents the song's valence.
B0 represents the intercept of the model function.
And the values B1 through B4 represent the coefficient estimates for each predictor.

To interpret both the impact and the strength of our predictor variables, we will pay attention to three key columns of this regression summary; Estimate, t-value, and p-value. The coefficient estimates tells us the log change in a song's popularity generated by a change in the predictor's value. Next, the t-values will tell us whether or not we can reject the null hypothesis, that our coefficient estimate is actually zero. Here, to conform with a 95% confidence interval, we will be looking for absolute values greater than 1.96. Lastly, a predictor’s p-value works with the t-value to confirm our rejection of the null hypothesis. Keeping in line with the same 95% confidence interval, we require values less than 0.05. Independent variables that satisfy both of the t and p-value conditions we have described above will, as a result, allow us to reject the null hypothesis, and thus, prove to be significant predictors of a song's popularity.

Estimates: As we can see, danceability and energy both have positive coefficients in our model. This means that gearing music toward these characteristics, that is, music that is quite energetic and easy to dance to, will result in higher levels of overall popularity. With an estimate of 1.35, energy appears to be the most significant factor in boosting song popularity, with a slight edge over danceability, which sits at an estimate of 1.28. On the other hand, both speechiness and valence have negative coefficients, suggesting that songs that include mostly spoken words, or are very upbeat and happy, are much less likely to reach significant levels of populaarity. Speechiness appears to be the more significant driving factor here with an estimate of -1.37, whereas valence produces an estimate of -0.83.

P and t-values: When analyzing our chart we can clearly see that for all predictors, both their p and t-values satisfy the conditions needed on a 95% confidence interval. This means that we can comfortably reject the null hypothesis that their true coefficient values are equal to zero. Thus, we can move on to validating these results and discussing their meaning on a larger scale.



## 4.2 Model Validation




# 5 Discussion

## Limitations

## Future Work



# 6 Appendix


# 7 References












